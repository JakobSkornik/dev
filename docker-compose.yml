version: "3"

networks:
  devel-network:
    ipam:
      driver: default
      config:
        - subnet: 172.27.0.0/16

services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    container_name: namenode
    volumes:
      - /tmp/hdfs/namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=devel
    env_file:
      - ./env/hadoop-hive.env
    ports:
      - "50070:50070"
    networks:
      devel-network:
        ipv4_address: 172.27.1.5

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    container_name: datanode
    volumes:
      - /tmp/hdfs/datanode:/hadoop/dfs/data
      - ./data:/data
    env_file:
      - ./env/hadoop-hive.env
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    depends_on:
      - namenode
    ports:
      - "50075:50075"
    networks:
      devel-network:
        ipv4_address: 172.27.1.6

  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-server
    env_file:
      - ./env/hadoop-hive.env
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
      SERVICE_PRECONDITION: "hive-metastore:9083"
    ports:
      - "10000:10000"
    depends_on:
      - hive-metastore
    networks:
      devel-network:
        ipv4_address: 172.27.1.7

  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-metastore
    env_file:
      - ./env/hadoop-hive.env
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 hive-metastore-postgresql:5432"
    ports:
      - "9083:9083"
    depends_on:
      - hive-metastore-postgresql
    networks:
      devel-network:
        ipv4_address: 172.27.1.8

  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:2.3.0
    container_name: hive-metastore-postgresql
    networks:
      devel-network:
        ipv4_address: 172.27.1.9

  hue:
    image: gethue/hue:20191107-135001
    hostname: hue
    container_name: hue
    dns: 8.8.8.8
    ports:
      - "8888:8888"
    volumes:
      - ./env/hue.ini:/usr/share/hue/desktop/conf/z-hue.ini
    depends_on:
      - "database"
    networks:
      devel-network:
        ipv4_address: 172.27.1.13

  database:
    image: mysql:5.7
    container_name: database
    ports:
      - "33061:3306"
    command: --init-file /data/application/init.sql
    volumes:
      - /tmp/mysql/data:/var/lib/mysql
      - ./env/init.sql:/data/application/init.sql
    environment:
      MYSQL_ROOT_USER: root
      MYSQL_ROOT_PASSWORD: secret
      MYSQL_DATABASE: hue
      MYSQL_USER: root
      MYSQL_PASSWORD: secret
    networks:
      devel-network:
        ipv4_address: 172.27.1.14

  spark-master:
    image: bde2020/spark-master:2.4.0-hadoop2.7
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    env_file:
      - ./env/hadoop-hive.env
    networks:
      devel-network:
        ipv4_address: 172.27.1.10

  spark-worker-1:
    image: bde2020/spark-worker:2.4.0-hadoop2.7
    container_name: spark-worker-1
    environment:
      - SPARK_LOCAL_IP=spark-worker-1
      - SPARK_MASTER=spark://spark-master:7077
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - HIVE_CORE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://hive-metastore/metastore
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    env_file:
      - ./env/worker.sh
      - ./env/hadoop-hive.env
    volumes:
      - ./executors/worker-data:/opt/spark-data
      - ./executors/worker-app:/opt/spark-apps
    networks:
      devel-network:
        ipv4_address: 172.27.1.11

  spark-worker-2:
    image: bde2020/spark-worker:2.4.0-hadoop2.7
    container_name: spark-worker-2
    environment:
      - SPARK_LOCAL_IP=spark-worker-2
      - SPARK_MASTER=spark://spark-master:7077
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - HIVE_CORE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://hive-metastore/metastore
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    env_file:
      - ./env/worker.sh
      - ./env/hadoop-hive.env
    volumes:
      - ./executors/worker-data:/opt/spark-data
      - ./executors/worker-app:/opt/spark-apps
    networks:
      devel-network:
        ipv4_address: 172.27.1.12

  streamsets:
    image: streamsets/datacollector:3.13.0-latest
    container_name: streamsets
    hostname: streamsets
    ports:
      - "18630:18630"
    networks:
      devel-network:
        ipv4_address: 172.27.1.17

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    hostname: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      devel-network:
        ipv4_address: 172.27.1.15

  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    hostname: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_NUM_PARTITIONS: 12
      KAFKA_COMPRESSION_TYPE: gzip
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE: 'false'
      KAFKA_JMX_PORT: 9091
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    networks:
      devel-network:
        ipv4_address: 172.27.1.16

  datascience-notebook:
    image: jupyter/all-spark-notebook
    hostname: jupyter
    container_name: jupyter
    ports:
      - "8887:8888"
    volumes:
      - ./jupyter/packages/conda/:/opt/conda/
      - ./jupyter/work/:/home/jovyan/work/
      - ./jupyter/packages/R/:/usr/local/spark-3.0.1-bin-hadoop3.2/R/lib
      - ./executors/worker-data:/home/jovyan/data/
      - ./executors/worker-app:/home/jovyan/work/
    networks:
      devel-network:
        ipv4_address: 172.27.1.19

  akhq:
    image: tchiotludo/akhq
    container_name: akhq
    hostname: akhq
    volumes:
      - ./env/application.yml:/app/application.yml
    ports:
      - "8079:8080"
    depends_on:
      - kafka
      - schema-registry
    networks:
      devel-network:
        ipv4_address: 172.27.1.20
  
  schema-registry:
    image: confluentinc/cp-schema-registry
    container_name: schema-registry
    depends_on:
      - kafka
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "PLAINTEXT://kafka:9092"
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_LISTENERS: "http://0.0.0.0:8085"
      SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: INFO
    networks:
      devel-network:
        ipv4_address: 172.27.1.21

  connect:
    image: confluentinc/cp-kafka-connect
    container_name: connect
    depends_on:
      - kafka
      - schema-registry
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:9092
      CONNECT_REST_PORT: 8083
      CONNECT_REST_LISTENERS: http://0.0.0.0:8083
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_CONFIG_STORAGE_TOPIC: __connect-config
      CONNECT_OFFSET_STORAGE_TOPIC: __connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: __connect-status
      CONNECT_GROUP_ID: "kafka-connect"
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "true"
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8085
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "true"
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8085
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_PLUGIN_PATH: ' /usr/share/java/'
    networks:
      devel-network:
        ipv4_address: 172.27.1.22